name: Performance Testing

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      duration:
        description: 'Test duration in minutes'
        required: true
        default: '5'
        type: number

env:
  NODE_VERSION: '18'
  PNPM_VERSION: '8.15.0'

jobs:
  # Lighthouse performance audit
  lighthouse-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    strategy:
      matrix:
        device: [desktop, mobile]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build application
        run: pnpm web:build
        env:
          NODE_ENV: production

      - name: Start application
        run: |
          pnpm web:start &
          sleep 30
        env:
          NODE_ENV: production

      - name: Run Lighthouse CI (${{ matrix.device }})
        uses: treosh/lighthouse-ci-action@v10
        with:
          configPath: './lighthouse.config.js'
          uploadArtifacts: true
          temporaryPublicStorage: true
          runs: 3
        env:
          DEVICE_TYPE: ${{ matrix.device }}

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v3
        with:
          name: lighthouse-results-${{ matrix.device }}
          path: |
            .lighthouseci/
            lighthouse-results.json

  # Load testing
  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Artillery
        run: npm install -g artillery@latest

      - name: Setup target environment
        run: |
          if [[ "${{ github.event.inputs.environment }}" == "production" ]]; then
            echo "TARGET_URL=https://bonsaisat.com" >> $GITHUB_ENV
          else
            echo "TARGET_URL=https://staging.bonsaisat.com" >> $GITHUB_ENV
          fi

      - name: Run load tests
        run: |
          artillery run tests/performance/load-test.yml \
            --target $TARGET_URL \
            --output load-test-results.json
        env:
          DURATION: ${{ github.event.inputs.duration || '5' }}

      - name: Generate load test report
        run: |
          artillery report load-test-results.json --output load-test-report.html

      - name: API stress test
        run: |
          artillery run tests/performance/api-stress.yml \
            --target $TARGET_URL \
            --output api-stress-results.json

      - name: Upload load test results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-results
          path: |
            load-test-results.json
            load-test-report.html
            api-stress-results.json

  # WebSocket performance testing
  websocket-performance:
    name: WebSocket Performance Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Setup target environment
        run: |
          if [[ "${{ github.event.inputs.environment }}" == "production" ]]; then
            echo "WEBSOCKET_URL=wss://ws.bonsaisat.com" >> $GITHUB_ENV
          else
            echo "WEBSOCKET_URL=wss://ws-staging.bonsaisat.com" >> $GITHUB_ENV
          fi

      - name: WebSocket connection test
        run: node tests/performance/websocket-connection.js
        env:
          WEBSOCKET_URL: ${{ env.WEBSOCKET_URL }}
          CONCURRENT_CONNECTIONS: 100
          TEST_DURATION: 300

      - name: WebSocket latency test
        run: node tests/performance/websocket-latency.js
        env:
          WEBSOCKET_URL: ${{ env.WEBSOCKET_URL }}
          PING_COUNT: 100

      - name: WebSocket stress test
        run: node tests/performance/websocket-stress.js
        env:
          WEBSOCKET_URL: ${{ env.WEBSOCKET_URL }}
          MAX_CONNECTIONS: 1000
          RAMP_UP_DURATION: 60

      - name: Upload WebSocket test results
        uses: actions/upload-artifact@v3
        with:
          name: websocket-performance-results
          path: |
            websocket-*.json
            websocket-*.html

  # Database performance testing
  database-performance:
    name: Database Performance Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Database query performance test
        run: node tests/performance/database-queries.js
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_TEST }}

      - name: Database connection pool test
        run: node tests/performance/database-pool.js
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_TEST }}
          MAX_CONNECTIONS: 50

      - name: Upload database test results
        uses: actions/upload-artifact@v3
        with:
          name: database-performance-results
          path: |
            database-*.json
            database-*.html

  # Core Web Vitals monitoring
  core-web-vitals:
    name: Core Web Vitals Monitoring
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Playwright
        run: |
          npx playwright install --with-deps chromium

      - name: Setup target environment
        run: |
          if [[ "${{ github.event.inputs.environment }}" == "production" ]]; then
            echo "TARGET_URL=https://bonsaisat.com" >> $GITHUB_ENV
          else
            echo "TARGET_URL=https://staging.bonsaisat.com" >> $GITHUB_ENV
          fi

      - name: Measure Core Web Vitals
        run: node tests/performance/core-web-vitals.js
        env:
          BASE_URL: ${{ env.TARGET_URL }}

      - name: Performance budget check
        run: node tests/performance/performance-budget.js
        env:
          BASE_URL: ${{ env.TARGET_URL }}

      - name: Upload Core Web Vitals results
        uses: actions/upload-artifact@v3
        with:
          name: core-web-vitals-results
          path: |
            core-web-vitals-*.json
            performance-budget-*.json

  # Memory and CPU profiling
  profiling:
    name: Memory and CPU Profiling
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build application
        run: pnpm web:build
        env:
          NODE_ENV: production

      - name: Memory profiling
        run: |
          node --inspect --heap-prof apps/web/server.js &
          SERVER_PID=$!
          sleep 60
          kill $SERVER_PID
        env:
          NODE_ENV: production

      - name: CPU profiling
        run: |
          node --prof apps/web/server.js &
          SERVER_PID=$!
          sleep 60
          kill $SERVER_PID
          node --prof-process isolate-*.log > cpu-profile.txt

      - name: Analyze heap snapshot
        run: |
          node tests/performance/heap-analysis.js

      - name: Upload profiling results
        uses: actions/upload-artifact@v3
        with:
          name: profiling-results
          path: |
            *.heapprofile
            *.heapsnapshot
            cpu-profile.txt
            heap-analysis.json

  # Browser extension performance
  extension-performance:
    name: Browser Extension Performance
    runs-on: ubuntu-latest
    strategy:
      matrix:
        browser: [chrome, firefox]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Build extension
        run: |
          cd apps/browser-extension
          npm install
          npm run build:${{ matrix.browser }}

      - name: Extension performance test
        run: |
          cd apps/browser-extension
          npm run test:performance:${{ matrix.browser }}

      - name: Extension memory usage test
        run: |
          cd apps/browser-extension
          npm run test:memory:${{ matrix.browser }}

      - name: Upload extension performance results
        uses: actions/upload-artifact@v3
        with:
          name: extension-performance-${{ matrix.browser }}
          path: |
            apps/browser-extension/performance-*.json

  # AI service performance testing
  ai-performance:
    name: AI Service Performance Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: AI question generation performance
        run: node tests/performance/ai-question-generation.js
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}

      - name: AI response time benchmark
        run: node tests/performance/ai-response-time.js
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}

      - name: Upload AI performance results
        uses: actions/upload-artifact@v3
        with:
          name: ai-performance-results
          path: |
            ai-*.json

  # Performance regression detection
  performance-regression:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, load-testing, core-web-vitals]
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download performance results
        uses: actions/download-artifact@v3

      - name: Performance regression analysis
        run: node tests/performance/regression-analysis.js

      - name: Comment on PR with performance results
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            let comment = '## üöÄ Performance Test Results\n\n';
            
            // Add Lighthouse results
            if (fs.existsSync('lighthouse-results-desktop/lighthouse-results.json')) {
              const lighthouseResults = JSON.parse(fs.readFileSync('lighthouse-results-desktop/lighthouse-results.json', 'utf8'));
              comment += '### Lighthouse Scores (Desktop)\n';
              comment += `- Performance: ${Math.round(lighthouseResults.lhr.categories.performance.score * 100)}/100\n`;
              comment += `- Accessibility: ${Math.round(lighthouseResults.lhr.categories.accessibility.score * 100)}/100\n`;
              comment += `- Best Practices: ${Math.round(lighthouseResults.lhr.categories['best-practices'].score * 100)}/100\n`;
              comment += `- SEO: ${Math.round(lighthouseResults.lhr.categories.seo.score * 100)}/100\n\n`;
            }
            
            // Add Core Web Vitals
            if (fs.existsSync('core-web-vitals-results/core-web-vitals.json')) {
              const cwvResults = JSON.parse(fs.readFileSync('core-web-vitals-results/core-web-vitals.json', 'utf8'));
              comment += '### Core Web Vitals\n';
              comment += `- First Contentful Paint: ${cwvResults.fcp}ms\n`;
              comment += `- Largest Contentful Paint: ${cwvResults.lcp}ms\n`;
              comment += `- Cumulative Layout Shift: ${cwvResults.cls}\n`;
              comment += `- First Input Delay: ${cwvResults.fid}ms\n\n`;
            }
            
            // Add load test results
            if (fs.existsSync('load-test-results/load-test-results.json')) {
              const loadResults = JSON.parse(fs.readFileSync('load-test-results/load-test-results.json', 'utf8'));
              comment += '### Load Test Results\n';
              comment += `- Average Response Time: ${loadResults.aggregate.latency.mean}ms\n`;
              comment += `- 95th Percentile: ${loadResults.aggregate.latency.p95}ms\n`;
              comment += `- Requests per second: ${loadResults.aggregate.rps.mean}\n`;
              comment += `- Error rate: ${(loadResults.aggregate.counters['errors.total'] || 0) / loadResults.aggregate.counters['http.requests'] * 100}%\n\n`;
            }
            
            // Check for regressions
            if (fs.existsSync('regression-analysis.json')) {
              const regressionResults = JSON.parse(fs.readFileSync('regression-analysis.json', 'utf8'));
              if (regressionResults.hasRegressions) {
                comment += '‚ö†Ô∏è **Performance regressions detected!**\n\n';
                regressionResults.regressions.forEach(regression => {
                  comment += `- ${regression.metric}: ${regression.change}\n`;
                });
                comment += '\n';
              } else {
                comment += '‚úÖ No performance regressions detected\n\n';
              }
            }
            
            comment += '_Performance tests run automatically on every PR. [View detailed results in Actions artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})_';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Performance monitoring setup
  monitoring-setup:
    name: Setup Performance Monitoring
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, load-testing, core-web-vitals]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Update DataDog metrics
        run: |
          curl -X POST "https://api.datadoghq.com/api/v1/series" \
          -H "Content-Type: application/json" \
          -H "DD-API-KEY: ${{ secrets.DATADOG_API_KEY }}" \
          -d '{
            "series": [
              {
                "metric": "bonsai.performance.lighthouse.score",
                "points": [['$(date +%s)', 85]],
                "tags": ["environment:staging", "category:performance"]
              }
            ]
          }'

      - name: Update performance baselines
        run: |
          echo "Updating performance baselines in monitoring systems..."
          # This would typically update baseline metrics in your monitoring system

  # Notification
  notify-results:
    name: Notify Performance Results
    runs-on: ubuntu-latest
    needs: [
      lighthouse-audit,
      load-testing,
      websocket-performance,
      core-web-vitals
    ]
    if: always() && (github.event_name == 'schedule' || failure())
    steps:
      - name: Notify performance issues
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          fields: repo,message,commit,author,action,eventName,ref,workflow
          text: |
            üêå Performance test failures detected!
            
            Environment: ${{ github.event.inputs.environment || 'staging' }}
            
            Please review the performance test results and investigate any regressions.
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_PERFORMANCE }}

      - name: Notify scheduled results
        if: github.event_name == 'schedule'
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          fields: repo,message,commit,author,action,eventName,ref,workflow
          text: |
            üìä Daily performance test results
            
            Status: ${{ job.status }}
            Environment: Production
            
            Detailed results available in GitHub Actions artifacts.
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_PERFORMANCE }}